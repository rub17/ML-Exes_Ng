{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "#import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "from scipy.optimize import fmin_bfgs\n",
    "from scipy.optimize import fmin\n",
    "\n",
    "from scipy.io import loadmat #To Read .mat files\n",
    "import matplotlib.image as mpimg # \n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0,6.0)\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 400), (5000, 1), (25, 401), (10, 26))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = loadmat(\"data/ex3data1.mat\")['X']\n",
    "y = loadmat(\"data/ex3data1.mat\")['y']\n",
    "Weights = loadmat(\"data/ex3weights.mat\")\n",
    "Theta1 = Weights[\"Theta1\"]\n",
    "Theta2 = Weights[\"Theta2\"]\n",
    "X.shape, y.shape,Theta1.shape, Theta2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 401), (5000, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numSamples = X.shape[0] #m\n",
    "numFeatures = X.shape[1] #n - pixel #'s\n",
    "numNodes=Theta1.shape[0]\n",
    "num_labels=Theta2.shape[0]\n",
    "all_theta = np.zeros((num_labels, numFeatures+1))\n",
    "Xin = np.hstack((np.ones((numSamples,1)),X)) # Add a bias node for the input layer.\n",
    "yin = np.where(y==10,0,y) # Change 10 back to 0.\n",
    "Xin.shape,yin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trd1 = loadmat('data/ex4weights.mat')['Theta1']\n",
    "trd2 = loadmat('data/ex4weights.mat')['Theta2']\n",
    "nnparams = np.append(trd1.flatten(), trd2.flatten())\n",
    "nnparams.shape\n",
    "Xin[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "def nnCstFun(nnparams,input_size,hidden_size,sample_size,num_labels,\n",
    "             x,y,lamb):\n",
    "    theta1 = nnparams[0:(input_size+1)*hidden_size].reshape(hidden_size,input_size+1) #+1 for bias node.\n",
    "    theta2 = nnparams[(input_size+1)*hidden_size:].reshape(num_labels,hidden_size+1) #NEED TO FOLLOW THE ORIGINAL WAY TO UNRAVEL!!!!!!!!! DONT SKIP AHEAD.\n",
    "    z2 = x@theta1.T\n",
    "    a2 = np.hstack((np.ones((sample_size,1)),sigmoid(z2)))#add a bias node.\n",
    "    z3 = a2@theta2.T\n",
    "    h = sigmoid(z3)\n",
    "    J = 0\n",
    "    y10 = np.zeros((sample_size,num_labels))\n",
    "    for i in range(sample_size):\n",
    "        yi = np.zeros((10,1))\n",
    "        a = y[i][0]\n",
    "        yi[a-1]=1 #THIS IS STUPID... MISALIGNMENT FROM MATLAB DATA TO PYTHON.\n",
    "        J += (-np.log(h[i]).dot(yi)-np.log(1-h[i]).dot((1-yi)))\n",
    "    return J.item()/sample_size #return the value only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2876291651613187"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnCstFun(nnparams,400,25,5000,10,Xin,y,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidGradient(z):\n",
    "    \"\"\"\n",
    "    computes the gradient of the sigmoid function\n",
    "    \"\"\"\n",
    "    sigmoid = 1/(1 + np.exp(-z))\n",
    "    \n",
    "    return sigmoid *(1-sigmoid)\n",
    "def nnCostFunction(nn_params,input_layer_size, hidden_layer_size, num_labels,X, y,Lambda):\n",
    "    \"\"\"\n",
    "    nn_params contains the parameters unrolled into a vector\n",
    "    \n",
    "    compute the cost and gradient of the neural network\n",
    "    \"\"\"\n",
    "    # Reshape nn_params back into the parameters Theta1 and Theta2\n",
    "    Theta1 = nn_params[:((input_layer_size+1) * hidden_layer_size)].reshape(hidden_layer_size,input_layer_size+1)\n",
    "    Theta2 = nn_params[((input_layer_size +1)* hidden_layer_size ):].reshape(num_labels,hidden_layer_size+1)\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    J=0\n",
    "    X = np.hstack((np.ones((m,1)),X))\n",
    "    y10 = np.zeros((m,num_labels))\n",
    "    a1 = sigmoid(X @ Theta1.T)\n",
    "    a1 = np.hstack((np.ones((m,1)), a1)) # hidden layer\n",
    "    a2 = sigmoid(a1 @ Theta2.T) # output layer\n",
    "    \n",
    "    for i in range(1,num_labels+1):\n",
    "        y10[:,i-1][:,np.newaxis] = np.where(y==i,1,0)\n",
    "    for j in range(num_labels):\n",
    "        J = J + sum(-y10[:,j] * np.log(a2[:,j]) - (1-y10[:,j])*np.log(1-a2[:,j]))\n",
    "    cost = 1/m* J\n",
    "    reg_J = cost + Lambda/(2*m) * (np.sum(Theta1[:,1:]**2) + np.sum(Theta2[:,1:]**2))\n",
    "    \n",
    "    # Implement the backpropagation algorithm to compute the gradients\n",
    "    \n",
    "    grad1 = np.zeros((Theta1.shape))\n",
    "    grad2 = np.zeros((Theta2.shape))\n",
    "    \n",
    "    for i in range(m):\n",
    "        xi= X[i,:] # 1 X 401\n",
    "        a1i = a1[i,:] # 1 X 26\n",
    "        a2i =a2[i,:] # 1 X 10\n",
    "        d2 = a2i - y10[i,:]\n",
    "        d1 = Theta2.T @ d2.T * sigmoidGradient(np.hstack((1,xi @ Theta1.T)))\n",
    "        grad1= grad1 + d1[1:][:,np.newaxis] @ xi[:,np.newaxis].T\n",
    "        grad2 = grad2 + d2.T[:,np.newaxis] @ a1i[:,np.newaxis].T\n",
    "        \n",
    "    grad1 = 1/m * grad1\n",
    "    grad2 = 1/m*grad2\n",
    "    \n",
    "    grad1_reg = grad1 + (Lambda/m) * np.hstack((np.zeros((Theta1.shape[0],1)),Theta1[:,1:]))\n",
    "    grad2_reg = grad2 + (Lambda/m) * np.hstack((np.zeros((Theta2.shape[0],1)),Theta2[:,1:]))\n",
    "    \n",
    "    return cost, grad1, grad2,reg_J, grad1_reg,grad2_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at parameters (non-regularized): 0.2876291651613188 \n",
      "Cost at parameters (Regularized): 0.38376985909092354\n"
     ]
    }
   ],
   "source": [
    "input_layer_size  = 400\n",
    "hidden_layer_size = 25\n",
    "num_labels = 10\n",
    "nn_params = np.append(Theta1.flatten(),Theta2.flatten())\n",
    "J,reg_J = nnCostFunction(nnparams, input_layer_size, hidden_layer_size, num_labels, X,y,1)[0:4:3]\n",
    "print(\"Cost at parameters (non-regularized):\",J,\"\\nCost at parameters (Regularized):\",reg_J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xpython",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
